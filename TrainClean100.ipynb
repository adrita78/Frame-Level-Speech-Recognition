{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULfYerJWBq6W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyGIrIuGN2Zd",
        "outputId": "a4139972-862c-4856-aa33-ad0550906d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torchsummaryX wandb --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gtg-7uyAN7B_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550a0edd-89b2-4683-b057-cbd40e335533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import optim\n",
        "from torch.nn import init\n",
        "import wandb\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device:\",device)\n",
        "\n",
        "\n",
        "from torchsummaryX import summary\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0l2CaWHOHDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a94deb-c30e-4dd3-fea7-c7eba26d617a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73274 sha256=691980e9ca4b5986864bb60f91b592a5e8b5d4ccbc07034d874b378b4f506118\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/67/7b/a6d668747974998471d29b230e7221dd01330ac34faebe4af4\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"adritadas\",\"key\":\"4d8e5e73b5126973227f2e938ba1249f\"}') \n",
        "    # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2CwhWiwOOrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7790c0-3646-4160-e038-791fa46aa595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11-785-s23-hw1p2.zip to /content\n",
            "100% 16.0G/16.0G [09:46<00:00, 28.4MB/s]\n",
            "100% 16.0G/16.0G [09:46<00:00, 29.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c 11-785-s23-hw1p2\n",
        "!mkdir '/content/data'\n",
        "\n",
        "!unzip -qo '11-785-s23-hw1p2.zip' -d '/content/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI03YisGOUH-"
      },
      "outputs": [],
      "source": [
        "data_dir_dev_clean = \"/content/data/11-785-s23-hw1p2/dev-clean\"\n",
        "\n",
        "data_dir_train_clean = \"/content/data/11-785-s23-hw1p2/train-clean-100\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEcMSSSmRIqR"
      },
      "outputs": [],
      "source": [
        "train_X = sorted(glob(os.path.join(data_dir_train_clean, 'mfcc','*.npy')))\n",
        "train_Y = sorted(glob(os.path.join(data_dir_train_clean, 'transcript','*.npy')))\n",
        "\n",
        "val_X = sorted(glob(os.path.join(data_dir_dev_clean, 'mfcc', '*.npy')))\n",
        "val_Y = sorted(glob(os.path.join(data_dir_dev_clean, 'transcript','*.npy')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INJKtzLVYH8_"
      },
      "outputs": [],
      "source": [
        "root = \"/content/data/11-785-s23-hw1p2/\"\n",
        "partition = \"dev-clean\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNfIk3zve9Qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c079b1-0c0a-45e7-e29d-bf8e831ba503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "PHONEMES = [\n",
        "            '[SIL]',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '[SOS]', '[EOS]']\n",
        "\n",
        "print(PHONEMES.index('[SIL]'))     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZMSUL_epsdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a5e99e-ceda-4037-e9d2-3c9438a268c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32lofNPBXkqN"
      },
      "outputs": [],
      "source": [
        "mfcc_dir = sorted(glob(os.path.join(root, partition, 'mfcc','*.npy')))\n",
        "transcript_dir = sorted(glob(os.path.join(root,partition,'transcript','*.npy')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqvnV5DxDXSv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emury05rULHu"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, phonemes = PHONEMES, context=0, partition= \"train-clean-360\"): # Feel free to add more arguments\n",
        "\n",
        "        self.context    = context\n",
        "        self.phonemes   = phonemes\n",
        "        \n",
        "        # TODO: MFCC directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        #self.mfcc_dir       = \n",
        "        # TODO: Transcripts directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        #self.transcript_dir = \n",
        "\n",
        "        # TODO: List files in sefl.mfcc_dir using os.listdir in sorted order\n",
        "        mfcc_names          =  sorted(glob(os.path.join(root, partition, 'mfcc','*.npy')))\n",
        "        # TODO: List files in self.transcript_dir using os.listdir in sorted order\n",
        "        transcript_names    = sorted(glob(os.path.join(root,partition,'transcript','*.npy')))\n",
        "\n",
        "        \n",
        "\n",
        "        # Making sure that we have the same no. of mfcc and transcripts\n",
        "        assert len(mfcc_names) == len(transcript_names) \n",
        "\n",
        "        self.mfccs, self.transcripts = [], []\n",
        "\n",
        "        # TODO: Iterate through mfccs and transcripts\n",
        "        for i in range(len(mfcc_names)):\n",
        "        #   Load a single mfcc\n",
        "            mfcc        = np.load(mfcc_names[i])\n",
        "        #   Do Cepstral Normalization of mfcc (explained in writeup)\n",
        "        #   Load the corresponding transcript\n",
        "            transcript  = np.load(transcript_names[i])[1:-1]  # Remove [SOS] and [EOS] from the transcript \n",
        "            # (Is there an efficient way to do this without traversing through the transcript?)\n",
        "            # Note that SOS will always be in the starting and EOS at end, as the name suggests.\n",
        "        #   Append each mfcc to self.mfcc, transcript to self.transcript\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript)\n",
        "\n",
        "        print(len(self.mfccs),len(self.transcripts))\n",
        "      \n",
        "\n",
        "        # NOTE:\n",
        "        # Each mfcc is of shape T1 x 27, T2 x 27, ...\n",
        "        # Each transcript is of shape (T1+2) x 27, (T2+2) x 27 before removing [SOS] and [EOS]\n",
        "\n",
        "        # TODO: Concatenate all mfccs in self.mfccs such that \n",
        "        # the final shape is T x 27 (Where T = T1 + T2 + ...) \n",
        "        self.mfccs          = np.concatenate(self.mfccs,axis=0)\n",
        "\n",
        "        # TODO: Concatenate all transcripts in self.transcripts such that \n",
        "        # the final shape is (T,) meaning, each time step has one phoneme output\n",
        "        self.transcripts    = np.concatenate(self.transcripts,axis=0)\n",
        "        # Hint: Use numpy to concatenate\n",
        "\n",
        "        # Length of the dataset is now the length of concatenated mfccs/transcripts\n",
        "        self.length = len(self.mfccs)\n",
        "\n",
        "        # Take some time to think about what we have done. \n",
        "        # self.mfcc is an array of the format (Frames x Features). \n",
        "        # Our goal is to recognize phonemes of each frame\n",
        "        # From hw0, you will be knowing what context is. \n",
        "        # We can introduce context by padding zeros on top and bottom of self.mfcc\n",
        "        self.mfccs = np.pad(self.mfccs,((context,context),(0,0)), 'constant',constant_values=0)# TODO\n",
        "\n",
        "        # The available phonemes in the transcript are of string data type\n",
        "        # But the neural network cannot predict strings as such. \n",
        "        # Hence, we map these phonemes to integers\n",
        "\n",
        "        # TODO: Map the phonemes to their corresponding list indexes in self.phonemes\n",
        "        self.transcripts = [PHONEMES.index(self.transcripts[i]) for i in range (len(self.transcripts))]\n",
        "        print(\"Length of mfccs:\" ,len(self.mfccs),\"Length of transcripts:\",len(self.transcripts))\n",
        "        # Now, if an element in self.transcript is 0, it means that it is 'SIL' (as per the above example)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        \n",
        "        # TODO: Based on context and offset, return a frame at given index with context frames to the left, and right.\n",
        "        frames =  self.mfccs[ind:ind+2*self.context+1, :].reshape(-1)\n",
        "        # After slicing, you get an array of shape 2*context+1 x 27. But our MLP needs 1d data and not 2d.\n",
        "        \n",
        "\n",
        "        frames      = torch.FloatTensor(frames) # Convert to tensors\n",
        "        phonemes    = torch.tensor(self.transcripts[ind])       \n",
        "\n",
        "        return frames, phonemes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ediOCn4AJ9EL"
      },
      "outputs": [],
      "source": [
        "class AudioTestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, phonemes = PHONEMES, context=0, partition= \"train-clean-360\"): # Feel free to add more arguments\n",
        "\n",
        "        self.context    = context\n",
        "        self.phonemes   = phonemes\n",
        "        \n",
        "        # TODO: MFCC directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        #self.mfcc_dir       = \n",
        "        # TODO: Transcripts directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        #self.transcript_dir = \n",
        "\n",
        "        # TODO: List files in sefl.mfcc_dir using os.listdir in sorted order\n",
        "        mfcc_names          =  sorted(glob(os.path.join(root, partition, 'mfcc','*.npy')))\n",
        "        # TODO: List files in self.transcript_dir using os.listdir in sorted order\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "        # Making sure that we have the same no. of mfcc and transcripts\n",
        "         \n",
        "\n",
        "        self.mfccs= []\n",
        "\n",
        "        # TODO: Iterate through mfccs and transcripts\n",
        "        for i in range(len(mfcc_names)):\n",
        "        #   Load a single mfcc\n",
        "            mfcc        = np.load(mfcc_names[i])\n",
        "        #   Do Cepstral Normalization of mfcc (explained in writeup)\n",
        "        #   Load the corresponding transcript\n",
        "           # Remove [SOS] and [EOS] from the transcript \n",
        "            # (Is there an efficient way to do this without traversing through the transcript?)\n",
        "            # Note that SOS will always be in the starting and EOS at end, as the name suggests.\n",
        "        #   Append each mfcc to self.mfcc, transcript to self.transcript\n",
        "            self.mfccs.append(mfcc)\n",
        "          \n",
        "\n",
        "        \n",
        "          \n",
        "\n",
        "        # NOTE:\n",
        "        # Each mfcc is of shape T1 x 27, T2 x 27, ...\n",
        "        # Each transcript is of shape (T1+2) x 27, (T2+2) x 27 before removing [SOS] and [EOS]\n",
        "\n",
        "        # TODO: Concatenate all mfccs in self.mfccs such that \n",
        "        # the final shape is T x 27 (Where T = T1 + T2 + ...) \n",
        "        self.mfccs          = np.concatenate(self.mfccs,axis=0)\n",
        "\n",
        "        # TODO: Concatenate all transcripts in self.transcripts such that \n",
        "        # the final shape is (T,) meaning, each time step has one phoneme output\n",
        "        \n",
        "        # Hint: Use numpy to concatenate\n",
        "\n",
        "        # Length of the dataset is now the length of concatenated mfccs/transcripts\n",
        "        self.length = len(self.mfccs)\n",
        "\n",
        "        # Take some time to think about what we have done. \n",
        "        # self.mfcc is an array of the format (Frames x Features). \n",
        "        # Our goal is to recognize phonemes of each frame\n",
        "        # From hw0, you will be knowing what context is. \n",
        "        # We can introduce context by padding zeros on top and bottom of self.mfcc\n",
        "        self.mfccs = np.pad(self.mfccs,((context,context),(0,0)), 'constant',constant_values=0)# TODO\n",
        "\n",
        "        # The available phonemes in the transcript are of string data type\n",
        "        # But the neural network cannot predict strings as such. \n",
        "        # Hence, we map these phonemes to integers\n",
        "\n",
        "        # TODO: Map the phonemes to their corresponding list indexes in self.phonemes\n",
        "        \n",
        "        # Now, if an element in self.transcript is 0, it means that it is 'SIL' (as per the above example)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        \n",
        "        # TODO: Based on context and offset, return a frame at given index with context frames to the left, and right.\n",
        "        frames =  self.mfccs[ind:ind+2*self.context+1, :].reshape(-1)\n",
        "        # After slicing, you get an array of shape 2*context+1 x 27. But our MLP needs 1d data and not 2d.\n",
        "        \n",
        "\n",
        "        frames      = torch.FloatTensor(frames) # Convert to tensors\n",
        "               \n",
        "\n",
        "        return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zw_AZS57L2p"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'epochs'        : 8,\n",
        "    'batch_size'    : 1024*8,\n",
        "    'context'       : 25,\n",
        "    'init_lr'       : 1e-3,\n",
        "    'architecture'  : 'unkown'\n",
        "    # Add more as you need them - e.g dropout values, weight decay, scheduler parameters\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fPPIIYT7RZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae71c35-10ab-437c-bb63-13220134d54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28539 28539\n",
            "Length of mfccs: 36091207 Length of transcripts: 36091157\n",
            "2703 2703\n",
            "Length of mfccs: 1928254 Length of transcripts: 1928204\n"
          ]
        }
      ],
      "source": [
        "#TODO: Create a dataset object using the AudioDataset class for the training data \n",
        "train_data = AudioDataset(root, phonemes = PHONEMES, context=25, partition= \"train-clean-100\")\n",
        "\n",
        "# TODO: Create a dataset object using the AudioDataset class for the validation data \n",
        "val_data = AudioDataset(root, phonemes = PHONEMES, context=25, partition= \"dev-clean\")\n",
        "\n",
        "# TODO: Create a dataset object using the AudioTestDataset class for the test data \n",
        "test_data = AudioTestDataset(root, phonemes = PHONEMES, context=25, partition= \"test-clean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFBmYIcnLuKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b5ab27-d8e6-495f-9ca0-14c6e0989836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size     :  8192\n",
            "Context        :  25\n",
            "Input size     :  1377\n",
            "Output symbols :  42\n",
            "Train dataset samples = 36091157, batches = 4406\n",
            "Validation dataset samples = 1928204, batches = 236\n",
            "Test dataset samples = 1934138, batches = 237\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data, \n",
        "    num_workers = 4,\n",
        "    batch_size  = config['batch_size'], \n",
        "    pin_memory  = True,\n",
        "    shuffle     = True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_data, \n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_data, \n",
        "    num_workers = 2, \n",
        "    batch_size  = config['batch_size'], \n",
        "    pin_memory  = True, \n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Batch size     : \", config['batch_size'])\n",
        "print(\"Context        : \", config['context'])\n",
        "print(\"Input size     : \", (2*config['context']+1)*27)\n",
        "print(\"Output symbols : \", len(PHONEMES))\n",
        "\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVyhbg8oL0vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a45c045-979d-48e7-ef85-d7ebad1f56a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8192, 1377]) torch.Size([8192])\n"
          ]
        }
      ],
      "source": [
        "for i, data in enumerate(train_loader):\n",
        "  \n",
        "    frames, phoneme = data\n",
        "    print(frames.shape, phoneme.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W69YQow26ZJB"
      },
      "outputs": [],
      "source": [
        "# Implement dropout,scheduler,kaiming\n",
        "class TrainModel(torch.nn.Module):\n",
        "     def __init__(self,in_features,out_features):\n",
        "        super(TrainModel,self).__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            \n",
        "            torch.nn.Linear(in_features , 1024),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.Dropout(p=0.15),\n",
        "\n",
        "            torch.nn.Linear(1024,1024),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.Dropout(p=0.15),\n",
        "\n",
        "            torch.nn.Linear(1024,2048),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(2048),\n",
        "            torch.nn.Dropout(p=0.25),\n",
        "\n",
        "            torch.nn.Linear(2048,2048),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(2048),\n",
        "            torch.nn.Dropout(p=0.15),\n",
        "\n",
        "            torch.nn.Linear(2048,2048),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(2048),\n",
        "            torch.nn.Dropout(p=0.2),\n",
        "\n",
        "            torch.nn.Linear(2048,2048),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(2048),\n",
        "            torch.nn.Dropout(p=0.2),\n",
        "\n",
        "            torch.nn.Linear(2048,2048),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(2048),\n",
        "            torch.nn.Dropout(p=0.15),\n",
        "\n",
        "            torch.nn.Linear(2048,1024),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.Dropout(p=0.15),\n",
        "\n",
        "            torch.nn.Linear(1024,out_features),\n",
        "          \n",
        "          )\n",
        "\n",
        "     def forward(self,x):\n",
        "       out = self.model(x)\n",
        "\n",
        "       return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_loader):\n",
        "    frames, phonemes = data\n",
        "    print(frames.shape, phonemes.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyyY8bEjxEvP",
        "outputId": "6789fc60-febf-492b-9bc1-e69b73a8b28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8192, 1377]) torch.Size([8192])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx-J-yQKPORA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7246d01c-6b60-4cd7-ebf0-588f1d6896a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainModel(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=1377, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.15, inplace=False)\n",
            "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.15, inplace=False)\n",
            "    (8): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): Dropout(p=0.25, inplace=False)\n",
            "    (12): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "    (13): ReLU()\n",
            "    (14): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): Dropout(p=0.15, inplace=False)\n",
            "    (16): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "    (17): ReLU()\n",
            "    (18): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): Dropout(p=0.2, inplace=False)\n",
            "    (20): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "    (21): ReLU()\n",
            "    (22): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (23): Dropout(p=0.2, inplace=False)\n",
            "    (24): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "    (25): ReLU()\n",
            "    (26): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): Dropout(p=0.15, inplace=False)\n",
            "    (28): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (29): ReLU()\n",
            "    (30): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): Dropout(p=0.15, inplace=False)\n",
            "    (32): Linear(in_features=1024, out_features=42, bias=True)\n",
            "  )\n",
            ")\n",
            "=========================================================================\n",
            "                         Kernel Shape  Output Shape     Params  Mult-Adds\n",
            "Layer                                                                    \n",
            "0_model.Linear_0         [1377, 1024]  [8192, 1024]  1.411072M  1.410048M\n",
            "1_model.ReLU_1                      -  [8192, 1024]          -          -\n",
            "2_model.BatchNorm1d_2          [1024]  [8192, 1024]     2.048k     1.024k\n",
            "3_model.Dropout_3                   -  [8192, 1024]          -          -\n",
            "4_model.Linear_4         [1024, 1024]  [8192, 1024]    1.0496M  1.048576M\n",
            "5_model.ReLU_5                      -  [8192, 1024]          -          -\n",
            "6_model.BatchNorm1d_6          [1024]  [8192, 1024]     2.048k     1.024k\n",
            "7_model.Dropout_7                   -  [8192, 1024]          -          -\n",
            "8_model.Linear_8         [1024, 2048]  [8192, 2048]    2.0992M  2.097152M\n",
            "9_model.ReLU_9                      -  [8192, 2048]          -          -\n",
            "10_model.BatchNorm1d_10        [2048]  [8192, 2048]     4.096k     2.048k\n",
            "11_model.Dropout_11                 -  [8192, 2048]          -          -\n",
            "12_model.Linear_12       [2048, 2048]  [8192, 2048]  4.196352M  4.194304M\n",
            "13_model.ReLU_13                    -  [8192, 2048]          -          -\n",
            "14_model.BatchNorm1d_14        [2048]  [8192, 2048]     4.096k     2.048k\n",
            "15_model.Dropout_15                 -  [8192, 2048]          -          -\n",
            "16_model.Linear_16       [2048, 2048]  [8192, 2048]  4.196352M  4.194304M\n",
            "17_model.ReLU_17                    -  [8192, 2048]          -          -\n",
            "18_model.BatchNorm1d_18        [2048]  [8192, 2048]     4.096k     2.048k\n",
            "19_model.Dropout_19                 -  [8192, 2048]          -          -\n",
            "20_model.Linear_20       [2048, 2048]  [8192, 2048]  4.196352M  4.194304M\n",
            "21_model.ReLU_21                    -  [8192, 2048]          -          -\n",
            "22_model.BatchNorm1d_22        [2048]  [8192, 2048]     4.096k     2.048k\n",
            "23_model.Dropout_23                 -  [8192, 2048]          -          -\n",
            "24_model.Linear_24       [2048, 2048]  [8192, 2048]  4.196352M  4.194304M\n",
            "25_model.ReLU_25                    -  [8192, 2048]          -          -\n",
            "26_model.BatchNorm1d_26        [2048]  [8192, 2048]     4.096k     2.048k\n",
            "27_model.Dropout_27                 -  [8192, 2048]          -          -\n",
            "28_model.Linear_28       [2048, 1024]  [8192, 1024]  2.098176M  2.097152M\n",
            "29_model.ReLU_29                    -  [8192, 1024]          -          -\n",
            "30_model.BatchNorm1d_30        [1024]  [8192, 1024]     2.048k     1.024k\n",
            "31_model.Dropout_31                 -  [8192, 1024]          -          -\n",
            "32_model.Linear_32         [1024, 42]    [8192, 42]     43.05k    43.008k\n",
            "-------------------------------------------------------------------------\n",
            "                          Totals\n",
            "Total params           23.51313M\n",
            "Trainable params       23.51313M\n",
            "Non-trainable params         0.0\n",
            "Mult-Adds             23.486464M\n",
            "=========================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Kernel Shape  Output Shape     Params  Mult-Adds\n",
              "Layer                                                                    \n",
              "0_model.Linear_0         [1377, 1024]  [8192, 1024]  1411072.0  1410048.0\n",
              "1_model.ReLU_1                      -  [8192, 1024]        NaN        NaN\n",
              "2_model.BatchNorm1d_2          [1024]  [8192, 1024]     2048.0     1024.0\n",
              "3_model.Dropout_3                   -  [8192, 1024]        NaN        NaN\n",
              "4_model.Linear_4         [1024, 1024]  [8192, 1024]  1049600.0  1048576.0\n",
              "5_model.ReLU_5                      -  [8192, 1024]        NaN        NaN\n",
              "6_model.BatchNorm1d_6          [1024]  [8192, 1024]     2048.0     1024.0\n",
              "7_model.Dropout_7                   -  [8192, 1024]        NaN        NaN\n",
              "8_model.Linear_8         [1024, 2048]  [8192, 2048]  2099200.0  2097152.0\n",
              "9_model.ReLU_9                      -  [8192, 2048]        NaN        NaN\n",
              "10_model.BatchNorm1d_10        [2048]  [8192, 2048]     4096.0     2048.0\n",
              "11_model.Dropout_11                 -  [8192, 2048]        NaN        NaN\n",
              "12_model.Linear_12       [2048, 2048]  [8192, 2048]  4196352.0  4194304.0\n",
              "13_model.ReLU_13                    -  [8192, 2048]        NaN        NaN\n",
              "14_model.BatchNorm1d_14        [2048]  [8192, 2048]     4096.0     2048.0\n",
              "15_model.Dropout_15                 -  [8192, 2048]        NaN        NaN\n",
              "16_model.Linear_16       [2048, 2048]  [8192, 2048]  4196352.0  4194304.0\n",
              "17_model.ReLU_17                    -  [8192, 2048]        NaN        NaN\n",
              "18_model.BatchNorm1d_18        [2048]  [8192, 2048]     4096.0     2048.0\n",
              "19_model.Dropout_19                 -  [8192, 2048]        NaN        NaN\n",
              "20_model.Linear_20       [2048, 2048]  [8192, 2048]  4196352.0  4194304.0\n",
              "21_model.ReLU_21                    -  [8192, 2048]        NaN        NaN\n",
              "22_model.BatchNorm1d_22        [2048]  [8192, 2048]     4096.0     2048.0\n",
              "23_model.Dropout_23                 -  [8192, 2048]        NaN        NaN\n",
              "24_model.Linear_24       [2048, 2048]  [8192, 2048]  4196352.0  4194304.0\n",
              "25_model.ReLU_25                    -  [8192, 2048]        NaN        NaN\n",
              "26_model.BatchNorm1d_26        [2048]  [8192, 2048]     4096.0     2048.0\n",
              "27_model.Dropout_27                 -  [8192, 2048]        NaN        NaN\n",
              "28_model.Linear_28       [2048, 1024]  [8192, 1024]  2098176.0  2097152.0\n",
              "29_model.ReLU_29                    -  [8192, 1024]        NaN        NaN\n",
              "30_model.BatchNorm1d_30        [1024]  [8192, 1024]     2048.0     1024.0\n",
              "31_model.Dropout_31                 -  [8192, 1024]        NaN        NaN\n",
              "32_model.Linear_32         [1024, 42]    [8192, 42]    43050.0    43008.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf35c19d-b340-4bc1-b3ab-3906dd582205\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_model.Linear_0</th>\n",
              "      <td>[1377, 1024]</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>1411072.0</td>\n",
              "      <td>1410048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_model.ReLU_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_model.BatchNorm1d_2</th>\n",
              "      <td>[1024]</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_model.Dropout_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_model.Linear_4</th>\n",
              "      <td>[1024, 1024]</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>1049600.0</td>\n",
              "      <td>1048576.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_model.ReLU_5</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_model.BatchNorm1d_6</th>\n",
              "      <td>[1024]</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_model.Dropout_7</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_model.Linear_8</th>\n",
              "      <td>[1024, 2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>2099200.0</td>\n",
              "      <td>2097152.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_model.ReLU_9</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_model.BatchNorm1d_10</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_model.Dropout_11</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_model.Linear_12</th>\n",
              "      <td>[2048, 2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4196352.0</td>\n",
              "      <td>4194304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_model.ReLU_13</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_model.BatchNorm1d_14</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_model.Dropout_15</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_model.Linear_16</th>\n",
              "      <td>[2048, 2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4196352.0</td>\n",
              "      <td>4194304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_model.ReLU_17</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_model.BatchNorm1d_18</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_model.Dropout_19</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_model.Linear_20</th>\n",
              "      <td>[2048, 2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4196352.0</td>\n",
              "      <td>4194304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_model.ReLU_21</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_model.BatchNorm1d_22</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_model.Dropout_23</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_model.Linear_24</th>\n",
              "      <td>[2048, 2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4196352.0</td>\n",
              "      <td>4194304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_model.ReLU_25</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_model.BatchNorm1d_26</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_model.Dropout_27</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_model.Linear_28</th>\n",
              "      <td>[2048, 1024]</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>2098176.0</td>\n",
              "      <td>2097152.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_model.ReLU_29</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_model.BatchNorm1d_30</th>\n",
              "      <td>[1024]</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_model.Dropout_31</th>\n",
              "      <td>-</td>\n",
              "      <td>[8192, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_model.Linear_32</th>\n",
              "      <td>[1024, 42]</td>\n",
              "      <td>[8192, 42]</td>\n",
              "      <td>43050.0</td>\n",
              "      <td>43008.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf35c19d-b340-4bc1-b3ab-3906dd582205')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf35c19d-b340-4bc1-b3ab-3906dd582205 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf35c19d-b340-4bc1-b3ab-3906dd582205');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "in_features = (2*config['context'] + 1 ) * 27\n",
        "out_features = len(train_data.phonemes)\n",
        "model = TrainModel(in_features,out_features).to(device)\n",
        "print(model)\n",
        "summary(model,frames.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yUOCX4MSMJQ"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = config['init_lr'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC0MF3gIb9FZ"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9fyrwI1cJPp"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer,criterion):\n",
        "\n",
        "  model.train()\n",
        "  tloss,tacc = 0,0\n",
        "  batch_bar = tqdm(total=len(train_loader),dynamic_ncols=True,leave=False,position=0,desc='Train')\n",
        "\n",
        "  for i, (frames,phonemes) in enumerate(dataloader):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    frames = frames.to(device)\n",
        "    phonemes = phonemes.to(device)\n",
        "\n",
        "    logits = model(frames)\n",
        "\n",
        "    loss = criterion(logits,phonemes)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    tloss += loss.item()\n",
        "    tacc  += torch.sum(torch.argmax(logits, dim=1)==phonemes).item()/logits.shape[0]\n",
        "\n",
        "    batch_bar.set_postfix(loss = \"{:.04f}\".format(float(tloss/(i+1))),\n",
        "                           acc =\"{:.04f}%\".format(float(tacc*100/(i+1))))\n",
        "    batch_bar.update()\n",
        "\n",
        "    del frames,phonemes,logits\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  batch_bar.close()\n",
        "  tloss /= len(train_loader)\n",
        "  tacc /= len(train_loader)\n",
        "\n",
        "  return tloss,tacc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ItoGxY8lYWE"
      },
      "outputs": [],
      "source": [
        "def eval(model, dataloader, optimizer,criterion):\n",
        "\n",
        "  model.eval()\n",
        "  vloss,vacc = 0,0\n",
        "  batch_bar = tqdm(total=len(val_loader),dynamic_ncols=True,leave=False,position=0,desc='Train')\n",
        "\n",
        "  for i, (frames,phonemes) in enumerate(dataloader):\n",
        "\n",
        "   \n",
        "\n",
        "    frames = frames.to(device)\n",
        "    phonemes = phonemes.to(device)\n",
        "    with torch.inference_mode():\n",
        "      logits = model(frames)\n",
        "      loss = criterion(logits,phonemes)\n",
        "\n",
        "   \n",
        "\n",
        "  \n",
        "    vloss += loss.item()\n",
        "    vacc  += torch.sum(torch.argmax(logits, dim=1)==phonemes).item()/logits.shape[0]\n",
        "\n",
        "    batch_bar.set_postfix(loss = \"{:.04f}\".format(float(vloss/(i+1))),\n",
        "                           acc =\"{:.04f}%\".format(float(vacc*100/(i+1))))\n",
        "    batch_bar.update()\n",
        "\n",
        "    del frames,phonemes,logits\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  batch_bar.close()\n",
        "  vloss /= len(val_loader)\n",
        "  vacc /= len(val_loader)\n",
        "\n",
        "  return vloss,vacc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TakuRi1jrThk"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "\n",
        "  print(\"\\nEpoch {}/{}\".format(epoch+1,config['epochs']))\n",
        "\n",
        "  curr_lr = float(optimizer.param_groups[0]['lr'])\n",
        "  train_loss, train_acc = train(model,train_loader,optimizer,criterion)\n",
        "  val_loss,val_acc = eval(model,val_loader,optimizer,criterion)\n",
        "\n",
        "  print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_acc*100, train_loss,curr_lr))\n",
        "  print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(val_acc*100 , val_loss))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}